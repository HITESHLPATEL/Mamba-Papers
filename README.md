# Mamba-Research-Hub [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

![](resources/mamba.jpeg)

ðŸ”¥ Mamba has proven its exceptional performance across diverse domains, often rivaling, and occasionally outperforming, state-of-the-art Transformer models. This repository presents a curated compilation of papers focusing on Mamba, complemented by accompanying code implementations. Additionally, it includes a variety of supplementary resources such as videos and blogs discussing about Mamba.


## Table of Content

- [Awesome-Mamba ](#awesome-mamba)
  - [Papers](#papers)
  - [Video Tutorials](#video-tutorials)
  - [Blogs](#blogs)
  - [Contributing](#contributing)

## Milestone Papers

|  Date  |       keywords       |    Institute    | Paper                                                                                                                                                                               | Code |
| :-----: | :------------------: | :--------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: |
| 2023-12 |     Mamba     |      Carnegie Mellon & Together AI     | [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/abs/2312.00752) |  [[Github]](https://github.com/state-spaces/mamba) |
| 2024-01 |     MambaByte     |      Cornell University     | [MambaByte: Token-free Selective State Space Model](https://arxiv.org/html/2401.13660v1) |  [[Github]]() |
| 2024-01 |     Vision Mamba     |      Huazhong University of Science and Technology, Horizon Robotics, Beijing Academy of Artificial Intelligence     | [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/pdf/2401.09417v1.pdf) |  [[Github]](https://github.com/hustvl/vim) |
| 2024-01 |     SegMamba     |      The Hong Kong University of Science and Technology & Beijing Academy of Artificial Intelligence     | [SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation ](https://arxiv.org/pdf/2401.13560v2.pdf) |  [[Github]](https://github.com/ge-xing/segmamba) |
| 2024-01 |       MoE-Mamba       |      University of Warsaw      | [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081)   |  [[Github]](https://github.com/llm-random/llm-random) |
| 2024-01 |         U-Mamba         |      Vector Institute for AI & University of Toronto      | [U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation](https://arxiv.org/abs/2401.04722) |   [[Github]](https://github.com/bowang-lab/U-Mamba) |
| 2024-01 |         Vivim         |      The Hong Kong University of Science and Technology      | [Vivim: a Video Vision Mamba for Video Object Segmentation ](https://arxiv.org/pdf/2401.14168v1.pdf) |   [[Github]](https://github.com/scott-yjyang/vivim) |
| 2024-01 |         VMamba         |      University of Chinese Academy of Sciences, HUAWEI Inc. & PengCheng Lab      | [VMamba: Visual State Space Model](https://arxiv.org/pdf/2401.10166.pdf) |   [[Github]](https://github.com/MzeroMiko/VMamba) |
 2024-01 |         MambaTab         |       University of Kentuck       | [MambaTab: A Simple Yet Effective Approach for Handling Tabular Data](https://arxiv.org/pdf/2401.08867.pdf) |   [[Github]]() |
| 2024-02 |         Graph-Mamba         |      University of Toronto      | [Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces ](https://browse.arxiv.org/pdf/2402.00789.pdf) |   [[Github]](https://github.com/bowang-lab/Graph-Mamba) |
| 2024-02 |         Swin-UMamba         |      Paul C. Lauterbur Research Center for Biomedical Imaging      | [Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining](https://arxiv.org/pdf/2402.03302.pdf) |   [[Github]](https://github.com/jiarunliu/swin-umamba) |
| 2024-02 |         BlackMamba         |      Zyphra       | [BlackMamba: Mixture of Experts for State-Space Models](https://arxiv.org/pdf/2402.03302.pdf) |   [[Github]]() |



## Video Tutorials
- [Yannic Kilcher] Mamba Paper Explained [Youtube](https://www.youtube.com/watch?v=9dSkvxS2EB0)
- [Umar Jamil] Mamba and S4 Explained [Youtube](https://www.youtube.com/watch?v=8Q_tqwpTpVU)
- [1littlecoder] MoE-Mamba [Youtube](https://www.youtube.com/watch?v=tZD3-uO0RJ0)


## Blogs
- [Joe El khoury] What is Mamba? [Medium](https://medium.com/@jelkhoury880/what-is-mamba-845987734ffc)
- [Vishal Rajput] Mamba: Can it replace Transformers? [Medium](https://medium.com/aiguys/mamba-can-it-replace-transformers-fe2032537916)
- [Azhar] Decoding Mamba [Medium](https://medium.com/ai-insights-cobet/decoding-mamba-the-next-big-leap-in-ai-sequence-modeling-ef3908060cb8)


## Contributing

This is an active repository and your contributions are always welcome!


---

If you have any question do not hesitate to contact me hitesh.patel945@gmail.com


